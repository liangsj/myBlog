{"meta":{"title":"liangSJ","subtitle":null,"description":null,"author":"liangSJ","url":"http://liangsj.top"},"pages":[{"title":"关于我","date":"2019-06-30T00:26:52.000Z","updated":"2019-06-30T00:38:06.592Z","comments":true,"path":"about/index.html","permalink":"http://liangsj.top/about/index.html","excerpt":"","text":"姓名： liangsjmail ：llsj123@163.com经历： 2010-2014 天津大学 2014-1017 中国矿业大学 2019- 百度技术栈 android php golang简述 对计算机充满热爱，喜欢探索自己的未知的领域 认可自己的职业，希望成为一名出色的工程师 希望成为一位有趣的人 希望通过blog总结自己的所学，帮助别人同时也找到自己的缺点"},{"title":"about/about.md","date":"2019-06-30T00:26:39.000Z","updated":"2019-06-30T00:26:40.006Z","comments":true,"path":"about-about-md/index.html","permalink":"http://liangsj.top/about-about-md/index.html","excerpt":"","text":""},{"title":"tafs","date":"2016-04-14T02:42:52.000Z","updated":"2019-06-25T00:00:59.959Z","comments":true,"path":"tafs/index.html","permalink":"http://liangsj.top/tafs/index.html","excerpt":"","text":""},{"title":"tags","date":"2016-04-14T02:42:57.000Z","updated":"2019-06-25T00:00:59.959Z","comments":true,"path":"tags/index.html","permalink":"http://liangsj.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"服务的搭建及其演变 -简单的单点服务搭建","slug":"server_1","date":"2019-06-27T16:00:00.000Z","updated":"2019-07-04T00:01:49.687Z","comments":true,"path":"2019/06/28/server_1/","link":"","permalink":"http://liangsj.top/2019/06/28/server_1/","excerpt":"","text":"服务的搭建及其演变 -简单的单点服务搭建在日常构建webapp应用中，最常见的就是一个代码模块，依赖一个数据库的架构。我们以一个简单的点赞系统来介绍架构是怎么一步一步由简单变得复杂的。 为了更好的在单机模拟分布式环境，也为了后续的方便部署，我引入的了docker。 上图是最简单 webapp 依赖单db的架构图 本节相关工具 golang : 一种接近于c的编程语言。在开发难度和性能上做到了比较好的平衡。采用协程+管道的设计，天然较好地支撑了并发,是目前较火的编程语言,这里主要用于编写代码逻辑。 mysql : 老牌的开源数据库,这里用于数据的持久化存储。 docker ： 近年较火的容器，主要综合和标准化了linux 下的namespace 和 cgroup 技术，并提供相应的手脚架和多种丰富的镜像用于环境的快速部署，资源隔离。本文主要用docker来进行环境的搭建和分布式的模拟 下面简单了解下docker比较重要的概念 镜像 : 打包好的软件合集，是创建容器的模板 容器 ：主要运行时候的实体，和镜像类似于 类和对象的关系 仓库 ：镜像市场，可以在上面下载到各种各样的镜像 上面的解释纯基于我个人理解，如果有不到位的地方请谅解,相关工具的使用方法，我会在使用中说清楚。具体的深度使用细节，可以参考相关的专业书籍。 开始搭建实验环境主要分为以下几步： docker,go 环境的安装，此类教程网上很多，这里就不在赘述 基于docker 的mysql 环境搭建 app代码的编写 基于docker的app部署基于docker的mysql 环境搭建数据库的搭建shell ocker network create front创建基于bridge模式名称为front的网络，后面我们会将所有部署的docker 容器添加进来 1docker run -d --name mysql -p 3306:3306 --env MYSQL_ROOT_PASSWORD=123456 --network front mysql 分析下这条docker命令的构成: docker run 是启动一个容器的命令 -d 参数指明是后台运行此容器 –name 是给容器命名，这里叫做 mysql -p 指明的是容器内端口和宿主机器端口的相互映映射,这里将宿主 3306 端口映射到容器的3306端口,一般mysql服务都使用3306端口 –network 参数表明要添加到哪个网络中，这里加入上面创建的front网络中 mysql 这个表明要在哪个镜像上创建容器，这里选择的是mysql的原生镜像。当镜像存在是会直接使用，不然docker eneeger 会替我们从网上进行下载 –env 参数表面要设置的环境变量，采用的是key=value的参数形式，我们这里把mysql root 的密码设置为 123456 输入 docker containers ls -a 看到我们的mysql容器已经搭建完成 数据库管理员及表结构的创建1mysql -h127.0.0.1 -P3306 -uroot -p123456 在我们的宿主机器上登录我们的mysql，如果你的宿主机器内没有mysql 客户端，也可以用如下命令登录 mysql 容器内，进行mysql的管理1docker exec -it mysql /bin/bash 执行下面sql语句1create database praise; 创建一个点赞数据库 12CREATE USER 'test'@'%' IDENTIFIED BY 'test';GRANT ALL ON *.* TO 'test'@'%'; 创建一个用户名和密码都是 test 的账号,并给此账号赋予最高权限 1ALTER USER 'test'@'%' IDENTIFIED WITH mysql_native_password BY 'test'; 更改这个用户的验证方式，这一步的目的主要是解决某些低版本的mysql客户端验证不通过的问题。 123456789CREATE TABLE `praise_count` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id', `resource_id` bigint(20) NOT NULL DEFAULT '0' COMMENT '资源id', `count` bigint(20) NOT NULL DEFAULT '0' COMMENT '次数', `ctime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'create time', `mtime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'modify time', PRIMARY KEY (`id`), UNIQUE KEY `resource_id` (`resource_id`)) ENGINE=InnoDB AUTO_INCREMENT=1968180 DEFAULT CHARSET=latin1 COLLATE=latin1_bin ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8 COMMENT='praise_count' 创建 点赞 数据表结构&emsp;到这里，我们一个可用于项目的数据库已经搭建完成&emsp;本教程放在真正的生产环境中需要注意的是： docker并不适用存储类的服务，存储类服务一般都占用大量磁盘，难以迁移没有必要部署在容器中。这里只是方便搭建环境，所以采用。 数据库的账号给予权限过高，密码过于简单，存在安全风险。 app 代码的编写这里的app相对比较简单，只实现两个接口。123456` /praise/set?resource_id=&#123;int&#125;` 点赞次数自增` /praise/get?resource_id=&#123;int&#125;` 查询点赞次数resource_id get参数，传入点赞资源的唯一id 本项目除了依赖mysql的驱动，其余都使用go的原生工具12go get -u github.com/go-sql-driver/mysql#安装go 的mysql驱动 下面进入代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package mainimport ( \"database/sql\" \"encoding/json\" \"flag\" \"fmt\" \"io\" \"log\" \"net/http\" \"strconv\" _ \"github.com/go-sql-driver/mysql\")//c/s协议返回的json的结构体// &#123;// errno : -1/0, 错误码，0代表正常// errmsg: \"\" , 错误信息// data : &#123;// resourceID : 111, 资源id，用于表示唯一的一条资源// count : 1 , 此资源被点赞的次数// Ctime : 1231231, 此项被创建的时间// &#125;//type Response struct &#123; Errno int `json:\"errno\"` ErrMsg string `json:\"errmsg\"` Data *Item `json:\"data\"`&#125;type Item struct &#123; ResourceID int64 `json:\"resourceID\"` Count int64 `json:\"count\"` Ctime int64 `json:\"ctime\"`&#125;// 数据库地址var dbAddr string// 数据库端口var port intfunc init() &#123; // 主要是用于支持可自定义传入数据库的地址和端口号 // 例如 go run main.go -mysql=mysql -port=3304 将数据库地址和端口号传入。此处也写有默认值 flag.StringVar(&amp;dbAddr, \"mysql\", \"mysql\", \"please input your mysql address,exp : 127.0.0.1\") flag.IntVar(&amp;port, \"port\", 3306, \"please input your mysql port,exp : 3304\")&#125;//测试接口func HelloServer(w http.ResponseWriter, req *http.Request) &#123; io.WriteString(w, \"hello, world!\\n\")&#125;func main() &#123; //命令端参数接解析 flag.Parse() log.Println(\"server init\") //注册三个接口，分别是 服务器测试接口，点赞接口，和点赞数获取接口 http.HandleFunc(\"/hello\", HelloServer) http.HandleFunc(\"/praise/get\", getPrasieCount) http.HandleFunc(\"/praise/set\", setPrasieCount) log.Println(\"server start\") //启动服务器，并监听80端口 log.Fatal(http.ListenAndServe(\":80\", nil))&#125;// 获取点赞数，主要逻辑func getPrasieCount(w http.ResponseWriter, req *http.Request) &#123; resourceID, err := getResourceIDFromGet(req) if err != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; dbOpenCommand := fmt.Sprintf(\"test:test@tcp(%s:%d)/praise?charset=utf8\", dbAddr, port) db, err := sql.Open(\"mysql\", dbOpenCommand) if err != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; defer db.Close() sql := fmt.Sprintf(\"select count,ctime from praise_count where resource_id = %d\", resourceID) rows, sqlerr := db.Query(sql) if sqlerr != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", sqlerr)) return &#125; defer rows.Close() res := Response&#123;Errno: 0&#125; var count, ctime int64 if rows.Next() &#123; rows.Scan(&amp;count, &amp;ctime) &#125; res.Data = &amp;Item&#123;ResourceID: resourceID, Count: count, Ctime: ctime&#125; retBytes, _ := json.Marshal(res) io.WriteString(w, string(retBytes))&#125;//添加点赞数func setPrasieCount(w http.ResponseWriter, req *http.Request) &#123; resourceID, err := getResourceIDFromGet(req) if err != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; dbOpenCommand := fmt.Sprintf(\"test:test@tcp(%s:%d)/praise?charset=utf8\", dbAddr, port) db, err := sql.Open(\"mysql\", dbOpenCommand) if err != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; defer db.Close() sql := fmt.Sprintf(\"INSERT INTO praise_count (resource_id,count ) VALUES (%d,1) ON DUPLICATE key UPDATE count=count+1\", resourceID) _, err = db.Query(sql) if err != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; retBytes, _ := json.Marshal(Response&#123;Errno: 0&#125;) io.WriteString(w, string(retBytes))&#125;//错误处理func returnErrMsg(w http.ResponseWriter, errno int, errmsg string) &#123; retBytes, _ := json.Marshal(Response&#123;Errno: errno, ErrMsg: errmsg&#125;) io.WriteString(w, string(retBytes))&#125;//解析get参数，获取资源IDfunc getResourceIDFromGet(req *http.Request) (int64, error) &#123; vars := req.URL.Query() resourceIDStr := vars.Get(\"resource_id\") resourceID, err := strconv.ParseInt(resourceIDStr, 10, 64) return resourceID, err&#125; 一个可以上线的代码已经编写完成。接下，将其打包到docker里。你可以想象，docker就是我们的一个服务器，或者是一个pass平台 12#启动docker的命令docker run -d -p 8080:80 -v $HOME/cluster-build/chapter_1/src/go/webapp:/go/src/webapp -v $HOME/cluster-build/chapter_1/src/sh:/sh --network front golang sh /sh/start.sh 这个docker run 命令较为复杂,很多参数的含义我们在上面已经介绍过了，我们介绍没有见过的吧 -v 文件挂载，将宿主机器上的文件挂载到容器中。其中我们把宿主机器的$HOME/cluster-build/chapter_1/src/go/webapp和 $HOME/cluster-build/chapter_1/src/sh文件夹分别映射到容器/go/src/webapp /sh下。多个 -v 参数可以进行多次映射。 –network 参数表明要添加到哪个网络中，这里加入上面创建的front网络中，和mysql处于同一个网络中，方便通讯 golang 这个表明要在哪个镜像上创建容器，这里选择的是golang的原生镜像。当镜像存在是会直接使用，不然docker eneeger 会替我们从网上进行下载 sh start.sh 后置命令，当容器创建完成是，执行这个命令，这里执行一个手写的脚本 start.sh 这个后置脚本主要做两件事情： 下载相关的依赖 将服务启动1go get -u github.com/go-sql-driver/mysql &amp;&amp; go run /go/src/webapp/main.go 大家看到 上面的挂载命令很复杂，一般大家都会把自己基于golang镜像，再打包出一个新的镜像。这里我们为了直观和方便调试，先采用这种方式进行挂载。后面，我们会用docker-compose 来管理所有的docker容器。 结果验证 用curl来访问我们期待的服务,资源id 为1 ，先访问 set 接口，在访问 set接口，结果为： set 接口请求示例 get 接口请求示例 到这里，最简单的单点服务就已经完成.","categories":[{"name":"program","slug":"program","permalink":"http://liangsj.top/categories/program/"}],"tags":[{"name":"webapp","slug":"webapp","permalink":"http://liangsj.top/tags/webapp/"},{"name":"docker","slug":"docker","permalink":"http://liangsj.top/tags/docker/"},{"name":"mysql","slug":"mysql","permalink":"http://liangsj.top/tags/mysql/"},{"name":"golang","slug":"golang","permalink":"http://liangsj.top/tags/golang/"}],"keywords":[{"name":"program","slug":"program","permalink":"http://liangsj.top/categories/program/"}]},{"title":"服务的搭建及其演变 - 高可用分布式缓存系统构建","slug":"server_2","date":"2019-06-27T16:00:00.000Z","updated":"2019-07-03T23:52:36.499Z","comments":true,"path":"2019/06/28/server_2/","link":"","permalink":"http://liangsj.top/2019/06/28/server_2/","excerpt":"","text":"前言在前一节中，已经实现了最简单的单点模式webapp 搭建。这种架构往往很难抗住高qps（每秒访问次数）的冲击。在业务发展，往往要进行改造。一套抗高访问量的系统往往是很复杂的，每一个组件都有其优化的点。在众多的环境中，数据库往往是最薄弱的一环.对于数据库优化，目前有几种 数据库上流进行缓存。将热数据存入内存数据库中，如常见的nosql数据库 redis、memcache；或者添加到webapp 的localcache中。这种方式优点是: 部署简单；执行简单。缺点是 入侵代码，增加代码复杂度；缓存数据存在不一致的风险；缓存命中率如果无法保证的话，也达不到保证下游安全的目的。 mysql 进行主从部署，一般来说主库只负责写操作，并将数据库内容同步更新到从库中。从库负责读操作。优点时：对代码入侵程度小；当某个库不可用时，我们可以进行切换。缺点是：在大规模的写操作时，可能会带来主从数据的延迟；主库压力大。 进行拆库拆表。 mysql 主从部署解决不了当数据急剧增加上，查询、插入过慢的问题。这时候一般我们会进行拆库拆表，这是一个痛苦的过程。其对业务代码入侵非常大。上述几个方法，可能会同时存在。在这里介绍下，最常见的添加缓存的方案。并进行扩展，描述 redis 怎么进行主从部署以及自动进行主从切换（mysql 主从部署的大体也是这么一个流程，就不重复介绍了）。 #相关工具本节会用到新的三个伙伴 redis ： 基于内存的 key-value 存储系统,能承受较高的qps，支持本地磁盘持久化备份。采用单线程的设计方案，逻辑相对简单。 docker-compose : docker 相关的手脚架工具，可以定义 、部署多个docker 容器。（相信大家到我前一节又长又臭的docker run 命令已经有些无奈了。docker - compose 能帮助我们解决这个问题） sentinel : 用于管理、监控 以及故障迁移 redis的工具 分布式环境构建缓存设计 - 基于docker单独redis搭建这里引入 docker-compose 来帮助我们管理日益复杂的docker 容器docker-compose 安装 pip install -U docker-compose```123456789101112131415安装好后，创建一个名为 docker-compose.yml文件 ```touch docker-compose.yml```,并往文件内添加以下内容```ymlversion: &apos;2.0&apos; # docker-compose.yml 的版本信息,这里写成2.Xservices: # 要定义的服务信息，这里除了需要添加之前的webapp 和 mysql 的运行环境，还需要添加redis服务 webapp: image: golang # 镜像名称 container_name: webapp # 生成的容器名称 ports: - 8080:80 # 宿主机器和容器的端口映射，这里是 宿主机器端口号:容器端口号 networks: - front # 此容器添加入的网络 volumes: - ./go/webapp:/go/src/webapp # 宿主机器目录和容器目录的映射， 这里是 宿主机器目录:容器内目录 - ./sh:/sh command: sh /sh/start.sh # 容器创建后要运行的命令 上面这段配置相当于 上节的 run -d -p 8080:80 -v $HOME/src/go/webapp:/go/src/webapp -v $HOME/src/sh:/sh --network front golang shlink1`` 123456789101112131415161718192021 mysql: image: mysql container_name: mysql ports: - 3306:3306 networks: - front environment: \"MYSQL_ROOT_PASSWORD\": \"123456\" # 容器内要设置的系统变量，这里是设置容器的mysql root密码 redis_master: image: redis container_name: redis_master networks: - front ports: - 7002:6379 restart: alwaysnetworks: # 定义网络信息 front: # 新网络名称 driver: bridge # 网络的模式,一般都选择bridge （docker中有多种网路模式，可以根据不同的使用场景进行使用，想深入了解，可以看docker官网介绍） webapp 中需要操作redis，这里依赖redigo这个开源的库，在启动之前把依赖下载的指令加入之前的start.sh 中,start.sh现在为 1go get -u github.com/go-sql-driver/mysql &amp;&amp; go get -u github.com/garyburd/redigo/redis &amp;&amp; go run /go/src/webapp/main.go docker-compose.yml 完成后，在当前目录下执行 up -d```,常见容器1输入 ```docker container ls -a 看到我们的redis，mysql，webapp已经跑起来了 代码改写基本的开发环境已经搭建完毕，现在改写我们之前的webapp 代码这里先添加 三个关于缓存操作的代码添加缓存12345678910111213//将点赞数放入redis_master缓存中func setToCache(resourceID int64, praiseCount int64) error &#123; conn, err := redis.Dial(\"tcp\", \"redis_master:6379\") //连接redis, host:port形式，host是上面定义的容器名称，port 是redis容器的redis服务端口号 if err != nil &#123; return err &#125; defer conn.Close() //const praise_count_cache_key_fmt string = \"resource_%d_prasie_cache\" key := fmt.Sprintf(praise_count_cache_key_fmt, resourceID) _, err = conn.Do(\"SET\", key, praiseCount) //将结果放入redis中 return err&#125; 清除缓存123456789101112131415161718192021222324252627282930//清除缓存数据func CleanCache(resourceID int64) error &#123; conn, err := redis.Dial(&quot;tcp&quot;, &quot;redis_master:6379&quot;) if err != nil &#123; return err &#125; defer conn.Close() key := fmt.Sprintf(praise_count_cache_key_fmt, resourceID) _, err = conn.Do(&quot;DEL&quot;, key) return err&#125;```go&lt;br&gt;从缓存中获取数据&lt;br&gt;``` go//从redis_master中获取点赞数func getFromCache(resourceID int64) (int64, error) &#123; conn, err := redis.Dial(&quot;tcp&quot;, &quot;redis_master:6379&quot;) if err != nil &#123; return 0, err &#125; defer conn.Close() key := fmt.Sprintf(praise_count_cache_key_fmt, resourceID) praiseCount, err := redis.Int64(conn.Do(&quot;GET&quot;, key)) if err != nil &#123; return 0, err &#125; return praiseCount, nil&#125; 接下来修改主流程里面的代码删除缓存操作放在写操作内，保证缓存一致12345678910111213func setPrasieCount(w http.ResponseWriter, req *http.Request) &#123; ..... //省略代码，如需要看上一节，在git中下载 _, err = db.Query(sql) if err != nil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; CleanCache(resourceID) //在添加点赞数是删除缓存 retBytes, _ := json.Marshal(Response&#123;Errno: 0&#125;) io.WriteString(w, string(retBytes))&#125; 读取缓存1234567891011121314151617181920212223func getPrasieCount(w http.ResponseWriter, req *http.Request) &#123; ... //省略参数获取部分 praiseCount, err := getFromCache(resourceID) // 从缓存读取点赞数 if err != nil &amp;&amp; err != redis.ErrNil &#123; returnErrMsg(w, -1, fmt.Sprintf(\"%v\", err)) return &#125; if err != redis.ErrNil &#123; //当缓存内有数据时直接返回 res := &amp;Response&#123;Errno: 0, Data: &amp;Item&#123;ResourceID: resourceID, Count: praiseCount&#125;&#125; retBytes, _ := json.Marshal(res) setToCache(resourceID, praiseCount) io.WriteString(w, string(retBytes)) return &#125; ......//省略从数据库读取数据部分 setToCache(resourceID, count) //缓存内没有数据，将从数据库里面读到的数据放入缓存中，以便下次使用 retBytes, _ := json.Marshal(res) io.WriteString(w, string(retBytes))&#125; 从上述代码中，可以看到，在读取点赞数时，先读缓存，如果缓存有数据我们直接当做结果进行返回。如果结果中没有数据，在进行数据库查询，并将查询结果放回redis-cache中。当有足够的高的缓存命中率时，能很好减少到下游db的流量，从而达到保护db的目的在写点赞数时，会把redis cache的数据进行删除，从而保证下次直读db，保证数据的一致性。存在缓存设计的风险点，当缓存删除失败时，会造成缓存数据和db数据不一致，对于要求数据强一致的业务不能这么进行设计 主从结构的分流设计 - 基于docker带有主从结构的redis 搭建至此，保护db的目的已经达到了。假设缓存流量持续上涨，缓存命中率也较高的情况下。redis-cache会成为新的瓶颈，除了在redis -cache 上在加一层在服务器上的local-cache外。我们还有第二个解决方案 ，进行主从结构的部署,（这里提供redis的解决方案，db也可以参考这种方案）。 redis 本身就支持主从结构的部署，只需要简单的命令 --slaveof ``` 即可12下面解决往docker-compose.yml添加新服务 redis_slave_1: image: redis ports: - 7003:6379 restart: always container_name: redis_slave_1 command: redis-server --slaveof redis_master 6379 #启动一个redis服务，并设置成为redis_master的从库 networks: - front image: redis restart: always redis_slave_2: image: redis ports: - 7004:6379 restart: always container_name: redis_slave_2 networks: - front image: redis restart: always command: redis-server --slaveof redis_master 6379 123456789101112131415161718修改完成后，执行 ```docker-compose up -d``` 镜像重新部署&#123;%img /images/2_compose_ret2.png%&#125;结果显示，我们两个redis 的从库已经部署好了### 代码改写下面进行读写入口的改写```go//从redis_master中获取点赞数func getFromCache(resourceID int64) (int64, error) &#123; conn, err := redis.Dial(&quot;tcp&quot;, &quot;redis_slave_1:6379&quot;) //更改读逻辑的redis入口 if err != nil &#123; return 0, err &#125; ....//省略其他逻辑 return praiseCount, nil&#125; 最后，写缓存流量在redis_master 主库上，读流量在从库上（从库如果有写操作会进行保存），大大减少redis master主库上的流量，从而达到分流的目的 自动主从切换 - 基于docker的sentine 环境搭建通过以上两个设计，系统稳定性已经上升了一个档次。但，我们观察到，主库现在又面临着单点的问题。如果主库出现可用性问题，结果往往是灾难的。我们需要套机制来进行监控主库和稳定性和当出现问题时，能进行主从切换,我们依旧以redis为例sentinel作为最常用的redis 监控、主从切换工具而被广泛应用。首先，先进行sentinel配置的编写,保存为 sentinel.conf123456port 26379 # sentinel 的服务端口dir /tmp # 工作文件目录sentinel monitor master redis_master 6379 1 # 对redis主库进行监听 后面三个参数的意思分别是 ： 主库的host，主库的端口，当 1 个sentinel 检查出现错误后，自动进行主从切换sentinel down-after-milliseconds master 30000 # 心跳检查，当主库在30000 ms内没有应答，则认为其已经不可用，进行容灾操作 代码改写结果验证生产环境中的注意点","categories":[],"tags":[{"name":"webapp","slug":"webapp","permalink":"http://liangsj.top/tags/webapp/"},{"name":"docker-compose","slug":"docker-compose","permalink":"http://liangsj.top/tags/docker-compose/"},{"name":"redis","slug":"redis","permalink":"http://liangsj.top/tags/redis/"},{"name":"sentinel","slug":"sentinel","permalink":"http://liangsj.top/tags/sentinel/"}],"keywords":[]},{"title":"tree","slug":"tree","date":"2016-05-31T05:44:28.000Z","updated":"2019-06-25T00:00:59.936Z","comments":true,"path":"2016/05/31/tree/","link":"","permalink":"http://liangsj.top/2016/05/31/tree/","excerpt":"","text":"前言 好久没有更新我的博客了，最近快开始校招了。因为长期在外面做开发，加上离考研已经很久了。数据结构的知识都已经记得模模糊糊了。为了准备笔试，同时提高自己的计算机素养。自己试着回忆了一下，树结构的基本算法。 数据结构 二叉树存储解构是一个数据两个指针。换到java中，就是一个变量，两个引用 123456public static class Node&#123; public Node left; public Node right; public int val; &#125; 二叉树的建立 二叉树能顺序存储，也能链式存储。但是链式存储更能直观的表现出二叉树的特征。下面这个算法是由顺序存储结构生成链式存储结构。我把没有数据的结点在数组中用”-1”表示（貌似很多教材都用’＃’表示）。12345678910111213141516public Node buildTree(int[] nums,int i) &#123; // TODO Auto-generated method stub if(i &gt; nums.length -1)&#123; return null; &#125; if(nums[i]== -1 )&#123; return null; &#125; Node n = new Node(); n.val = nums[i]; n.left = buildTree(nums, 2*i); n.right = buildTree(nums, 2*i+1); return n; &#125; 二叉树的遍历 二叉树的遍历是考试中最经常考的内容，他的递归遍历代码优雅，简洁。有一种让人过目不忘的感觉。这里就不给出了，但是值得注意的是，一个结点被无论是哪种遍历，在递归的时候，它已经被被经过了三次。上面上一张考研材料上的图， 标注为１的，是前序遍历标注为2的，是中序遍历标注为3的，是后序遍历 还有一点头脑风暴的感觉，就是用栈来实现递归，其实思想也不难，就是有点绕。总体都是，按照上述路线入栈，前中序当他是最后叶子结点时候，出栈。后序遍历是经过第二次时候才出栈。(原谅我令人可怜的语文水平吧)下面是我写的非递归前序遍历。123456789101112131415void preorder2(Node root)&#123; Stack&lt;Node&gt; s = new Stack&lt;Node&gt;(); while(root !=null || !s.isEmpty())&#123; while(root!= null)&#123; s.push(root); System.out.print(root.val + &quot;---&gt;&quot;); &#125; if(!s.isEmpty() &amp;&amp; root == null)&#123; root=s.pop(); root=root.right; &#125; &#125; &#125; 层次遍历就更简单了，利用队列实现，当队列不为空，出列，读取他的数据，并将他的左右孩子入队列。有趣的是，层次遍历正好是数的线性存储。默认数组位置 ０ 不存放。1234567891011void queueOrder(Node root)&#123; List&lt;Node&gt; l = new ArrayList&lt;Node&gt;(); l.add(root); while(l.size() != 0)&#123; Node n=l.remove(0); System.out.print(&quot; &quot; + n.val); if(n.left != null) l.add(n.left); if(n.right != null) l.add(n.right); &#125;&#125; 其他树是非常有用的数据结构，包括平衡二叉树，二叉查询树，哈夫曼编码都是树有意思的应用。我还没有总结成代码。但是，这些东西挺有趣，包括java中很多容器都利用到树的知识。比如TreeMap ，就是红黑树。 练习代码 拿出来献丑了12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package com.may.eighteen;import java.util.ArrayList;import java.util.List;import java.util.Stack;public class Solution &#123; public static class Node&#123; public Node left; public Node right; public int val; &#125; static int[] nums = &#123;-1,1,2,3,4,5,6,7,8,9&#125;; public static void main(String args[])&#123; Solution s = new Solution(); Node root = s.buildTree(nums,1); System.out.print(&quot;-----hello----&quot;); s.preorder(root); System.out.println(&quot;&quot;); s.preorder(root); System.out.println(&quot;&quot;); s.queueOrder(root); System.out.println(&quot;&quot;); System.out.print(s.findNodeCount(root)); &#125; public Node buildTree(int[] nums,int i) &#123; // TODO Auto-generated method stub if(i &gt; nums.length -1)&#123; return null; &#125; if(nums[i]== -1 )&#123; return null; &#125; Node n = new Node(); n.val = nums[i]; n.left = buildTree(nums, 2*i); n.right = buildTree(nums, 2*i+1); return n; &#125; public void buileTree(int[] preOrder, int[] inOrder, Node root)&#123; if(root == null) return; &#125; void queueOrder(Node root)&#123; List&lt;Node&gt; l = new ArrayList&lt;Node&gt;(); l.add(root); while(l.size() != 0)&#123; Node n=l.remove(0); System.out.print(&quot; &quot; + n.val); if(n.left != null) l.add(n.left); if(n.right != null) l.add(n.right); &#125; &#125; void preorder(Node root)&#123; if(root == null) return; System.out.print(root.val + &quot;---&quot;); preorder(root.left); preorder(root.right); &#125; void preorder2(Node root)&#123; Stack&lt;Node&gt; s = new Stack&lt;Node&gt;(); while(root !=null || !s.isEmpty())&#123; while(root!= null)&#123; s.push(root); System.out.print(root.val + &quot;---&gt;&quot;); &#125; if(!s.isEmpty() &amp;&amp; root == null)&#123; root=s.pop(); root=root.right; &#125; &#125; &#125; int findNodeCount(Node root)&#123; if(root == null)&#123;return 0;&#125; return findNodeCount(root.left) + findNodeCount(root.right) +1; &#125; &#125;","categories":[],"tags":[{"name":"data struct","slug":"data-struct","permalink":"http://liangsj.top/tags/data-struct/"}],"keywords":[]},{"title":"concurrency","slug":"concurrency","date":"2016-04-26T03:27:31.000Z","updated":"2019-06-25T00:00:59.935Z","comments":true,"path":"2016/04/26/concurrency/","link":"","permalink":"http://liangsj.top/2016/04/26/concurrency/","excerpt":"","text":"并发编程 并发编程属于编程技术里面较难掌握的一部分。就我个人而言，日常编写代码中。出现莫名奇妙且很难调试复现出来的bug一样都出现在这一块。由于jvm线程调度有随意性。sun公司也没有将此部分代码公开。我们很难了解里面的具体实现。只能说，在遇上对线程或者多进程编程的需求时，要保持谨慎的态度。一般你觉得这部分会出错，那就会出错。 从操作系统的角度来说，进程是资源分配的最小单位，线程则是系统调度的最小单位。利用并发变成的技术，可以将任务分为不同的部分。充分利用CPU时间。在面对较长时间阻塞时，采用并发技术所带来的好处能覆盖掉上下文切换的损失。当然，进程或者线程增加了同步的成本，在操作同一资源时，同步往往是最难处理的。 在不同的设计中，对并发技术也做了诸多限制。就android而言，在ViewRoot下绘制的UI界面，是不支持多线程的，也就是，只能在主线程内绘制UI界面（当然，有特定的组件能支持多线程绘制）。确保线程的安全。 java 中的并发java是支持多线程的语言。特别是在一些GUI项目和web jsp项目上，多线程是不可或缺的。1、Runnable Thread在java中，Runnable 这个接口可以理解为一下可以放在任务队列上的一个任务。个人认为取名为Runnable有些令人困惑，叫task会不会更加清晰。Thread 这个类可以把他看成一个线程，其中他的start方法，会向系统申请一个线程，并执行写在run()中的代码。在写多线程任务时，一般有两种写法，实现接口 Runnable 将要执行的代码段写入run()中，或者直接继承Thread，复写run().两种方法都可以采用。但是我一般选用第一种，java不支持继承多类。但是可以实现多个接口。要把extends宝贵的位置留出来。另外值得注意的一点。 123MyThread t1 = new MyThread();t1.run();//没有用到多线程，相当于直接调用了一个方法t1.start();//正确的调用方式 在代码中，new MyThread()虽然没有指定引用指向他，但是系统会自动给他生成一个引用。所有在它没有死亡之前，是不会被gc回收的。 2、后台线程我个人的理解中，后台线程属于重要程度比较低的线程。一般的作用是支持前台线程。从而，在前台线程全部结束后，后台线程也会被强行结束。1t1.setDaemon(true);//设置此线程为后台线程的方法。后台线程值得注意的有两点，1、在一般情况下卸载finally关键字后面的代码肯定是会运行的。但是后台线程比较特殊，在系统前台线程全部死亡后，写在后台线程finally后的代码就不会运行。2、由后台线程生成的新的线程，也都是后台。 java thread 锁众所周知，多线程最麻烦问题之一就是同步问题。java语言也设计了一些方便帮我们解决这些问题。1、原子操作根据《java编程思想》一书的建议，自己最好不要依赖于原子操作，因为一般的程序员没有那么好的掌控力。但是了解一下一般的原子操作对我们理解程序还是很有帮助的。 1、对于处理除long，double类型之外的基本变量都是原子性的。（因为long、double在加载时是分别度两次32位）2、在java中，自增操作不是设计出原子性的3、java中封装了一些原子类，如AtomicInteger、AtomicLong等，用法也很简单。 2、synchronized 和volatile Lock.classvolatile:是一个轻量级锁，修饰变量时，相当于说明，被修改是，会刷新缓存。保障别的线程读到这个变量时是最新修改的synchronized最常用的锁，通常形式是synchronized function { //代码}在一个对象中，维持着一个锁变量。当线程进入这个，此线程相当于获得了这个锁的使用权。其他线程在没有获得锁之前，禁止进入此代码段。同时，他还维持着一个变量，函数调用栈进入不同的加synchronized的方法，变量会增加，退出会减少，直至0才会释放锁synchronized(this){ //代码}可以锁定代码块 Lock.class这个是一个显示锁，在代码上来看，不够优雅。达到的效果和synchronized差不多。但是可以在获得锁失败时做出处理。 wait() notify()从前面，我们知道。在synchronized关键字下，会获得一个锁。但是有时候，我们需要进程之间的同步，有时候需要释放这个锁给另外的线程使用。直至另外一个线程处理完我们所需要的任务。我们在接着跑下去。1234567synchronized&#123; wait();&#125;synchronized&#123; notify();&#125;当我们持有线程锁后，wait()方法让我们暂时放弃锁。当前线程被挂起。直至另外锁调用notify()/notifyAll()(notify()是解除单个wait()，notifyAll()能解除多个wait()).才能继续运行剩余的代码块。值得注意的是，当线程没有持有锁的时候，调用这几个方法。都会抛出异常。 线程中的异常java异常机制在小型项目中，十分有用。方便我们分离异常发生代码块和处理代码块。在多线程编程中，异常是不可以跨线程传递的。也就说，我们需要在线程的调用栈中，及时的处理我们的异常。有时候，这样容易造成代码混乱。逻辑不够优雅。sun提供了一个方法，让我们处理跨线程异常。每个Thread对象都允许附着一个异常处理器。Thread.UncaughtExceptionHandle.uncaughtException().会在线程未被捕获异常时候死亡时被调用。 新类库中的构件我想想很多用java的程序员最喜欢的就是其中各种各样的框架，能大大减少开发时间。说句题外话，我们这一批刚刚从学校走出来的学生。在学校常常学习着大量的计算机底层知识，用着c实现各种算法。很多人，包括曾经的我。都觉得用太多成型的框架，会大大减弱编程能力。但是我现在觉得，能用好用的工具，很好的解决问题，才是最重要的。包括现在流行的python，越来越多的细节被隐藏在各种组件中，大大减轻了程序员的压力。 java SE5 中的java.util.concurrent 引入了很多解决并发问题的工具。以下是我看中的总结。 CountDownLatch它被用来同步一个或者多个任务，强制他们等待有其他任务执行的一组操作。它相当与一个计数器，在调用await()后，他将进入等待状态。直至countDown()能将初始化量减少到0;。 CyclicBarrier和CountDownLatch相似，这个也是管理多个线程工作的拦截器。用法更更加灵活。设想一个场景。一个很庞大的矩阵，我们对所有元素进行求和计算。我们的想法是，每一列用一个线程进行计算，在把所有的结果加起来。那么，在我们进行完每一列计算后，调用await()等待,其他的线程执行完计算才能执行加操作。在new CycliBarrier的生成方法中，能传入一个参数Runnable,复写它的run方法，当所有调用和barrier有关的线程进入await（）。执行这个Runnable。（这个Runnable在最后进入的线程中执行） Semaphore正常的锁，我们可以理解它是一个许可证。当一个线程调用他的acquire()方法时，他将获得许可证。当调用realse()方法后，许可证才被释放。android的wakeLock就是这样实现的。 Exchanger从名字可以看出是用来进行线程之间的交换的。在两个线程在结束之前，都会获得由exchanger.exchange(Object)返回的对象。 乐观锁在原子操作的数据类型中，如AtomicInteger中，可以利用compareAndSet方法，修改其中的数据。以提高效率。乐观锁实现的原理是：判断是数据是不是最新的。如果是最新的就可以操作，而如果不是就循环判断，直到数据是最新的。这样可以省去加锁和解锁消耗的时间。 android中的线程解决方案在android开发中，我们一般通过Handler - Looper - MessageQueue来进行进程中的通信和同步，包括android FrameWork在进入ActivityThread时也会生成一个 Handler H 来负责管理剩下所有的操作。我觉得android设计的同步实行，更适合我们普通人的思维。具体是这样的。每个一个Thread都可以绑定一个MessageQueue，用于存放消息。当其里面不为空，loop将其取出，让后执行其回调。而hanler是发射器。用来将Message发射到其绑定的MessageQueue中。这样当，当线程1执行完操作，就可以将结果发射给线程2.线程2得到接着操作资源，接着执行操作。我个人觉得是一种比较优雅和符合普通人思维的方式。","categories":[],"tags":[{"name":"concurrency","slug":"concurrency","permalink":"http://liangsj.top/tags/concurrency/"}],"keywords":[]},{"title":"generics","slug":"generics","date":"2016-04-26T02:51:54.000Z","updated":"2019-06-25T00:00:59.935Z","comments":true,"path":"2016/04/26/generics/","link":"","permalink":"http://liangsj.top/2016/04/26/generics/","excerpt":"","text":"泛型的作用java 泛型是在JDK5 后出现的。其核心概念是：告诉编译器想使用什么类型，将其置于尖括号内。让编译器帮你处理细节。并做正确性的检测。","categories":[],"tags":[{"name":"generics","slug":"generics","permalink":"http://liangsj.top/tags/generics/"}],"keywords":[]},{"title":"我所理解的java反射","slug":"RIIT","date":"2016-04-20T11:24:29.000Z","updated":"2019-06-25T00:00:59.934Z","comments":true,"path":"2016/04/20/RIIT/","link":"","permalink":"http://liangsj.top/2016/04/20/RIIT/","excerpt":"","text":"为什么要使用反射 在面向对象的编程中，多态是最常用的概念。基本上，面向对象的思想之所以能这么流行，能出现多种灵活的设计模式，多态的特征是功不可没的。多态，使我们将抽象和具体隔离。使得父类给出接口，子类具体实现。降低了编程的复杂性。但在某些情况下，在我们将子类向上转型后，有希望知道这个类的具体类型，和操作某些子类特有的行为。这时候，反射能帮上我们的忙。 在某些情况了，你新的类在你的程序编译好很久后才会出现。比如：你从互联网上下载一段代码，你明确知道，这段代码代表的是一个类。可是，你怎么才能很使用它呢。反射就是我们用于解决这种问题的工具。 Class一切都是对象,是java的基本设计思想。在我们编写每一个.java文件后，编译器会将我们的.java文件编译成.class文件。当我们调用name.class的静态方法时，jvm的类加载器会将我们的class文件加载进内存。这个从侧面证实了，一个类的构造函数也是静态函数，虽然他们没有static关键字。class也是一个对象。我们可以利用这个对象。来创建“常规”的对象.从上面的描述，我们也可以了解到，java是动态加载的语言。当类首次被引用的时候，才会被加载进内存。这点c++中就很难做到。 121、Class.forname(className); //可以不是使用对象，拿到这个类的Class引用。2、Class name = name.class; //类字面常量生成Class引用。在编译时就会受到检查 值得注意的一点，使用方法1获得类是的引用时，其静态成员会被初始化。使用方法2时，其静态成员只有在其类的静态成员第一次被使用时，才会被初始化。 泛型和Class注意点 假设 存在 父类 Father 子类 Child extends father1Class&lt;Child&gt; c=Child.classm因为编译时就知道c.getSuperclass()得到的不只是Father这个类，更明确到他是Child的父类。 isInstance 和 isInstanceOfisInstanceOf和isInstance这两个方法都是用来确定对象的类型。但是用起来有一些差别。总体来说，isInstanceOf实在编译期间就能明确对象类型的。而isInstance实在运行期间才能确定。用法也稍微也不同123A a = new A();a.instanceOf A; //truea.getClass().instance(A);//true值得注意的是，isInstance比较影响效率，在能使用isInstanceOf 的情况下，尽可能的使用isInstanceOf 动态代理代理模式事实上就是在具体实现类中间加一个中间层。把具体实现隔离开来。在java中，出来能实现我们经常见到的代理模式，我们还能通过实现接口InvocationHanler来实现动态代理。 1234567891011public List getList(final List list)&#123; return (List) Proxy.newProxyInstance(DummyProxy.class.getClassLoader(), new Class[] &#123; List.class&#125; new InvocationHanler()&#123; public Object invoke(Object proxy, Method method Object[] args) throws Throwable&#123; if(&quot;add&quot;.equals(method.getName()))&#123; throw new UnsupportdOperationException(); &#125;else&#123; return method.invoke(list,args); &#125; &#125; &#125; );&#125; 上面例子是执行List.class的方法，如果遇到add方法，则抛出异常。剩下的方法正常执行。例子来自（http://www.infoq.com/cn/articles/cf-java-reflection-dynamic-proxy） 反射的危害事实上，反射是很强大的。但是伴随而来的是权限方面的难以管理。原则上来说，反射只要知道方法名，就能调用此方法。private关键字也起不到保护的作用。但是，有趣的是，final域相对是安全的，运行是，修改它，系统并不会抛出异常，但是事实上它的值并没有被修改。","categories":[],"tags":[{"name":"java reflection","slug":"java-reflection","permalink":"http://liangsj.top/tags/java-reflection/"}],"keywords":[]},{"title":"String","slug":"我对java-String的理解","date":"2016-04-19T09:50:05.000Z","updated":"2019-06-25T00:00:59.936Z","comments":true,"path":"2016/04/19/我对java-String的理解/","link":"","permalink":"http://liangsj.top/2016/04/19/我对java-String的理解/","excerpt":"","text":"我对java String的理解在java开发中，String几乎最常用的类型了。在系统中，字符串计算是十分耗费资源的。为此，sun在设计String是，采用了很多奇妙的设计。 String的不可变性在java设计中，String类型是不可变的。如12String s1 = &quot;abc&quot;;String s2 = s1.toUpperCase(); 实际上，s1依旧指向 abc ，而s2指 向新生成的ABC所在的新的地址。换句话说，String具有只读性。 String的 +大家都知道，在java中，是不允许对像C++一样操作符重载的。但是，对于String来说有点例外，它重载了，“+”、“+=”两个操作符号 在日常程序编写中，我是经常会编写字符串拼接的程序。如 String s = “I”+”love”+”CS”; 按照String不变性在推测，是不是在生成新的s时， 第一步：新生成”Ilove”对象 第二部：生成”IloveCS”对象 如果字符串拼接项很多，那么。那么中间就会生成很多对象。Gc也会不断的回收新生成的对象。在一个大型的程序中，如此低效率的行为，明显是不会被允许的。 事实上，在java编译中，实际上采用了new StringBuilder的方式，优化了这个问题。 上述过程，最终实现优化后，差不多如下 12345StringBuilder sb = new StringBuilder();sb.append(&quot;I&quot;);sb.append(&quot;love&quot;);sb.append(&quot;CS&quot;);String s = sb.toString(); 注意：在字符串拼接十分复杂的情况下，需要自己生成StringBuilder。单纯依靠编译器优化。可能依旧存在效率问题。 String 存储 String是一个非常有意思的类。在内存中存储的方式不同 当String s1= “abc” 时，String是存在静态区。且在静态区内，同一个字符串，在静态区，只能存有一份。 123String s2 = &quot;a&quot;;String s3 = &quot;a&quot;;s2 == s3 // true 注意： == 比较的是内存地址是否相等。如果是字符串内容是否相等，则用equal（） 123String s4 = new String(&quot;abc&quot;);是生成在堆内存中。String s5 = new String(&quot;abc&quot;);s4 == s5 //false String s6 = “abc” + new String(“cde”); 也是生成在堆内存中，因为new 后面只有在运行时才会被知道具体内容。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://liangsj.top/tags/java/"}],"keywords":[]},{"title":"Hello World","slug":"hello-world","date":"2016-03-26T03:27:31.000Z","updated":"2019-06-29T11:50:54.970Z","comments":true,"path":"2016/03/26/hello-world/","link":"","permalink":"http://liangsj.top/2016/03/26/hello-world/","excerpt":"","text":"大家好，这是我第一篇博文。按照程序员的惯例。第一篇文章应该是叫hello world吧 Quick Start建立博客的目的主要还是用来自娱自乐。偶尔记录一下自己的生活。新学到的技术，或者对以往技术的感悟。如果有人看的话。希望能对向我一样在学习中的人有所帮助。 platformaliyun centos 因为工作一直是用的linux发行版是ubuntu，但是最便宜的aliyun是centos的。为了省点钱，只能在centos上多折腾一点。估计我们这一代程序员，从在学校开始，接触的都是ubuntu。centos应该不是很多人用。好在基本的都差不多。遇到不相同的部分，概念迁移+google一下。基本也能解决。 toolsnginxnginx是web容器。我对其研究不深，暂时还是停留在只知道配置阶段。看了nginx官网的文档，我觉得它的反向代理很有用。对于服务器分流，减压。多服务器搭建应该很方便. nginx install12$ sudo yum -y install nginx centos 仓库中安装$ sudo systemctl start nginx 启动nginx 接下来输入你的aliyun IP地址就可以看到nginx的成功启动界面了。 nginx settingnginx 的配置文件在 /etc/nginx/nginx.conf1234$ cd /etc/nginx/$ sudo chmod +rw nginx.conf 将配置文件设置成当前用户可读写模式$ sudo mv nginx.conf nginx.cong.bak 备份配置文件，防止修改错误还能找会来$ sudo vim nginx.conf 用vim 打开文件 nginx.conf1234server&#123; root //标出根目录文件，就是一下hexo生产的静态文件 index index.php index.html index.htm 设置文件的名字格式&#125; hexohexo 是基于nodejs的静态博客生成工具。个人觉得还挺好用，主要还是操作简单hexo install123$ sudo yum -y install node 安装nodejs$ sudo yum -y install npm 安装nodejs的npm仓库$ npm install -g hexo-cli 安装hexo hexo 操作十分简单123$ hexo init 初始化当初文件夹，生成博客工程$ hexo g 生成静态文件$ hexo server 打开hexo调试服务器。如果提示错误，先安装hexo server组件 更多可以查看 hexo(http://hexo.io)官网","categories":[],"tags":[],"keywords":[]}]}